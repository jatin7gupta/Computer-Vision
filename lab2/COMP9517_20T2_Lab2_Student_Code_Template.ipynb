{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==3.4.2.17 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (3.4.2.17)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (from opencv-python==3.4.2.17) (1.19.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python==3.4.2.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python==3.4.2.17 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (3.4.2.17)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (from opencv-contrib-python==3.4.2.17) (1.19.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python==3.4.2.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (from matplotlib) (1.19.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\jatin\\anaconda3\\envs\\cv\\lib\\site-packages (0.5.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task1 Hint: (with sample code for the SIFT detector)\n",
    "# Initialize SIFT detector, detect keypoints, store and show SIFT keypoints of original image in a Numpy array\n",
    "# Define parameters for SIFT initializations such that we find only 10% of keypoints\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SiftDetector():\n",
    "    def __init__(self, norm=\"L2\", params=None):\n",
    "        self.detector=self.get_detector(params)\n",
    "        self.norm=norm\n",
    "\n",
    "    def get_detector(self, params):\n",
    "        if params is None:\n",
    "            params={}\n",
    "            params[\"n_features\"]=0\n",
    "            params[\"n_octave_layers\"]=3\n",
    "            params[\"contrast_threshold\"]=0.03\n",
    "            params[\"edge_threshold\"]=10\n",
    "            params[\"sigma\"]=1.6\n",
    "\n",
    "        detector = cv2.xfeatures2d.SIFT_create(\n",
    "                nfeatures=params[\"n_features\"],\n",
    "                nOctaveLayers=params[\"n_octave_layers\"],\n",
    "                contrastThreshold=params[\"contrast_threshold\"],\n",
    "                edgeThreshold=params[\"edge_threshold\"],\n",
    "                sigma=params[\"sigma\"])\n",
    "\n",
    "        return detector\n",
    "\n",
    "\n",
    "\n",
    "# Task2 Hint:\n",
    "# Upscale the image, compute SIFT features for rescaled image\n",
    "# Apply BFMatcher with defined params and ratio test to obtain good matches, and then select and draw best 5 matches\n",
    "\n",
    "# Task3 Hint: (with sampe code for the rotation)\n",
    "# Rotate the image and compute SIFT features for rotated image\n",
    "# Apply BFMatcher with defined params and ratio test to obtain good matches, and then select and draw best 5 matches\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# image: image to rotate\n",
    "# x:     x-coordinate of point we wish to rotate around\n",
    "# y:     y-coordinate of point we wish to rotate around\n",
    "# angle: degrees to rotate image by\n",
    "#\n",
    "# Returns a rotated copy of the original image\n",
    "def rotate(image, x, y, angle):\n",
    "    rot_matrix = cv2.getRotationMatrix2D((x, y), angle, 1.0)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    return cv2.warpAffine(image, rot_matrix, (w, h))\n",
    "\n",
    "# Get coordinates of center point.\n",
    "#\n",
    "# image:  Image that will be rotated\n",
    "# return: (x, y) coordinates of point at center of image\n",
    "def get_img_center(image):\n",
    "    height, width = image.shape[:2]\n",
    "    center = height // 2, width // 2\n",
    "\n",
    "    return center\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import image in gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('COMP9517_20T2_Lab2_Image.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1, part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1_a(img, name):\n",
    "    sift = SiftDetector()\n",
    "    detector = sift.get_detector(None)\n",
    "    \n",
    "    kp = detector.detect(img, None)\n",
    "    img = cv2.drawKeypoints(img,kp,img)\n",
    "    cv2.imwrite(name, img)\n",
    "\n",
    "\n",
    "task1_a(img.copy(), 'task1_A.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have experimented with both the approaches with trail and error. The n features method is straight simple and we just have to give N. For the contrast threshold, it will depend on the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sift_detector():\n",
    "    sift = SiftDetector()\n",
    "    params = {}\n",
    "    params[\"n_features\"] = 0\n",
    "    params[\"n_octave_layers\"] = 3\n",
    "    params[\"contrast_threshold\"] = 0.136\n",
    "    params[\"edge_threshold\"] = 10\n",
    "    params[\"sigma\"] = 1.6\n",
    "    detector = sift.get_detector(params)\n",
    "    return detector\n",
    "\n",
    "def get_sift_detector_n():\n",
    "    sift = SiftDetector()\n",
    "    params = {}\n",
    "    params[\"n_features\"] = 620\n",
    "    params[\"n_octave_layers\"] = 3\n",
    "    params[\"contrast_threshold\"] = 0.03\n",
    "    params[\"edge_threshold\"] = 10\n",
    "    params[\"sigma\"] = 1.6\n",
    "    detector = sift.get_detector(params)\n",
    "    return detector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1, part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [241, 241, 241],\n",
       "        [240, 240, 240],\n",
       "        [239, 239, 239]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [240, 240, 240],\n",
       "        [239, 239, 239],\n",
       "        [239, 239, 239]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [239, 239, 239],\n",
       "        [239, 239, 239],\n",
       "        [239, 239, 239]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[107, 107, 107],\n",
       "        [110, 110, 110],\n",
       "        [119, 119, 119],\n",
       "        ...,\n",
       "        [121, 121, 121],\n",
       "        [120, 120, 120],\n",
       "        [120, 120, 120]],\n",
       "\n",
       "       [[106, 106, 106],\n",
       "        [108, 108, 108],\n",
       "        [110, 110, 110],\n",
       "        ...,\n",
       "        [121, 121, 121],\n",
       "        [120, 120, 120],\n",
       "        [121, 121, 121]],\n",
       "\n",
       "       [[104, 104, 104],\n",
       "        [104, 104, 104],\n",
       "        [112, 112, 112],\n",
       "        ...,\n",
       "        [118, 118, 118],\n",
       "        [118, 118, 118],\n",
       "        [121, 121, 121]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def task1_b(img, name):\n",
    "    detector = get_sift_detector()\n",
    "\n",
    "    kp = detector.detect(img, None)\n",
    "    img = cv2.drawKeypoints(img, kp, img)\n",
    "    cv2.imwrite(name, img)\n",
    "    return img\n",
    "\n",
    "    \n",
    "task1_b(img.copy(), 'task1_B.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2(img, name):\n",
    "    # part a\n",
    "    scale_percent = 115 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    resized = cv2.resize(img, dim)\n",
    "    \n",
    "    # part b: increased to 710 from 625\n",
    "    resized_image = task1_b(resized, name+'_B.jpg')\n",
    "\n",
    "    # part c\n",
    "    '''\n",
    "    Yes, the key points are roughly the same as SIFT is scale independent. It only looks at the texture of objects.\n",
    "    '''\n",
    "\n",
    "    # part d\n",
    "    detector = get_sift_detector()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = detector.detectAndCompute(img, None)\n",
    "    kp2, des2 = detector.detectAndCompute(resized, None)\n",
    "\n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "    good = sorted(good, key=lambda x: x[0].distance)\n",
    "\n",
    "    # cv2.drawMatchesKnn expects list of lists as matches.\n",
    "    img3 = cv2.drawMatchesKnn(img, kp1, resized, kp2, good[:5], img, flags=2)\n",
    "    cv2.imwrite(name+'_D.jpg', img3)\n",
    "    \n",
    "\n",
    "task2(img.copy(), 'task2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task3(img, name):\n",
    "    # part a\n",
    "    rotated = imutils.rotate_bound(img, angle=60)\n",
    "\n",
    "    # part b\n",
    "    detector = get_sift_detector()\n",
    "    kp2, des2 = detector.detectAndCompute(rotated, None)\n",
    "\n",
    "    rotated_dist = cv2.drawKeypoints(rotated, kp2, rotated)\n",
    "    cv2.imwrite(name + '_B.jpg', rotated_dist)\n",
    "    \n",
    "    # part c\n",
    "    '''\n",
    "    Yes, the key points are roughly the same as SIFT is orientation independent. It only looks at the texture of objects. But we can see little variations. \n",
    "    '''\n",
    "    \n",
    "    # part d\n",
    "    kp1, des1 = detector.detectAndCompute(img, None)\n",
    "\n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "    good = sorted(good, key=lambda x: x[0].distance)\n",
    "\n",
    "    # cv2.drawMatchesKnn expects list of lists as matches.\n",
    "    img3 = cv2.drawMatchesKnn(img, kp1, rotated, kp2, good[:7], img, flags=2)\n",
    "    cv2.imwrite(name+'_D.jpg', img3)\n",
    "    \n",
    "\n",
    "task3(img.copy(), 'task3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
